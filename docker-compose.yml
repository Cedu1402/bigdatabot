services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.15.5
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - xpack.security.http.ssl.enabled=false
      - "ES_JAVA_OPTS=-Xms2g -Xmx2g"  # Limit heap to 2GB
    deploy:
      resources:
        limits:
          memory: 3G  # Limit container memory to 3GB
    ports:
      - "9200:9200"
    networks:
      - app_network
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data

  logstash:
    image: docker.elastic.co/logstash/logstash:8.15.5
    container_name: logstash
    ports:
      - "5000:5000" # For http input
      - "9600:9600" # For Logstash API
    environment:
      - "LOGSTASH_JAVA_OPTS=-Xms1g -Xmx1g"  # Set initial and max heap size to 1GB
    deploy:
      resources:
        limits:
          memory: 2G  # Limit container memory to 2GB
    volumes:
      - ./logstash.conf:/usr/share/logstash/pipeline/logstash.conf
    networks:
      - app_network

  kibana:
    image: docker.elastic.co/kibana/kibana:8.15.5
    container_name: kibana
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    depends_on:
      - elasticsearch
    networks:
      - app_network

  # Redis service for queue management
  redis:
    image: redis:alpine
    ports:
      - "6379:6379"
    networks:
      - app_network
    restart: always

  event_queue:
    build:
      context: .
      dockerfile: Dockerfile
    command: rq worker --url redis://redis:6379 EVENT_QUEUE
    environment:
      - REDIS_URL=redis
      - LOGSTASH_HOST=logstash
      - LOGSTASH_PORT=5000
    networks:
      - app_network
    depends_on:
      - redis
    restart: always
    deploy:
      replicas: 3

  token_queue:
    build:
      context: .
      dockerfile: Dockerfile
    command: rq worker --url redis://redis:6379 TOKEN_QUEUE
    environment:
      - REDIS_URL=redis
      - LOGSTASH_HOST=logstash
      - LOGSTASH_PORT=5000
    networks:
      - app_network
    depends_on:
      - redis
    restart: always
    deploy:
      replicas: 5

  trade_queue:
    build:
      context: .
      dockerfile: Dockerfile
    command: rq worker --url redis://redis:6379 TRADE_QUEUE
    environment:
      - REDIS_URL=redis
      - LOGSTASH_HOST=logstash
      - LOGSTASH_PORT=5000
    networks:
      - app_network
    depends_on:
      - redis
    restart: always
    deploy:
      replicas: 5

  price_watcher:
    build:
      context: .
      dockerfile: Dockerfile
    command: python bot/sol_price_watcher.py
    environment:
      - REDIS_URL=redis
      - LOGSTASH_HOST=logstash
      - LOGSTASH_PORT=5000
    networks:
      - app_network
    depends_on:
      - redis
    restart: always

  bot_main:
    build:
      context: .
      dockerfile: Dockerfile
    command: python bot/bot_main.py
    environment:
      - REDIS_URL=redis
      - LOGSTASH_HOST=logstash
      - LOGSTASH_PORT=5000
    networks:
      - app_network
    depends_on:
      - redis
    restart: always

  bot_stats:
    build:
      context: .
      dockerfile: Dockerfile
    command: python bot/bot_stats.py
    environment:
      - FLASK_APP=bot/bot_stats.py
      - FLASK_ENV=development
      - REDIS_URL=redis
      - LOGSTASH_HOST=logstash
      - LOGSTASH_PORT=5000
    networks:
      - app_network
    depends_on:
      - postgres
    ports:
      - "4359:4359"
    restart: always

  postgres:
    image: postgres:17
    container_name: postgres
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: bigdatabot
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    networks:
      - app_network

volumes:
  elasticsearch-data:
    driver: local
  postgres_data:
    driver: local

networks:
  app_network:
    driver: bridge