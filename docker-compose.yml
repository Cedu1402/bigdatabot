services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.15.5
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=true
      - ELASTIC_PASSWORD=${ELASTICSEARCH_PASSWORD}
    ports:
      - "9200:9200"
    networks:
      - app_network
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data

  logstash:
    image: docker.elastic.co/logstash/logstash:8.10.2
    container_name: logstash
    ports:
      - "5000:5000" # For http input
      - "9600:9600" # For Logstash API
    volumes:
      - ./logstash.conf:/usr/share/logstash/pipeline/logstash.conf
    environment:
      - ELASTICSEARCH_USERNAME=elastic
      - ELASTICSEARCH_PASSWORD=${ELASTICSEARCH_PASSWORD}
    networks:
      - app_network

  kibana:
    build:
      context: .
      dockerfile: Elastic.Dockerfile # Reference the custom Dockerfile
    container_name: kibana
    ports:
      - "5601:5601"
    environment:
      - "ELASTICSEARCH_HOSTS=http://elasticsearch:9200"
      - "ELASTICSEARCH_USERNAME=kibana_system"
      - "ELASTICSEARCH_PASSWORD=${KIBANA_SYSTEM_PASSWORD}"
      - "xpack.security.enabled=true"  # Enable security
    depends_on:
      - elasticsearch
    networks:
      - app_network

  # Redis service for queue management
  redis:
    image: redis:alpine
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    networks:
      - app_network
    command: [ "redis-server", "--appendonly", "yes" ] # Enables AOF for persistence
    restart: always

  event_queue:
    build:
      context: .
      dockerfile: Dockerfile
    command: rq worker --url redis://redis:6379 EVENT_QUEUE
    environment:
      - REDIS_URL=redis
      - LOGSTASH_HOST=logstash
      - LOGSTASH_PORT=5000
    networks:
      - app_network
    depends_on:
      - redis
    restart: always
    deploy:
      replicas: 1

  token_queue:
    build:
      context: .
      dockerfile: Dockerfile
    command: rq worker --url redis://redis:6379 TOKEN_QUEUE
    environment:
      - REDIS_URL=redis
      - LOGSTASH_HOST=logstash
      - LOGSTASH_PORT=5000
    networks:
      - app_network
    depends_on:
      - redis
    restart: always
    deploy:
      replicas: 1

  trade_queue:
    build:
      context: .
      dockerfile: Dockerfile
    command: rq worker --url redis://redis:6379 TRADE_QUEUE
    environment:
      - REDIS_URL=redis
      - LOGSTASH_HOST=logstash
      - LOGSTASH_PORT=5000
    networks:
      - app_network
    depends_on:
      - redis
    restart: always
    deploy:
      replicas: 1

  price_watcher:
    build:
      context: .
      dockerfile: Dockerfile
    command: python bot/sol_price_watcher.py
    environment:
      - REDIS_URL=redis
      - LOGSTASH_HOST=logstash
      - LOGSTASH_PORT=5000
    networks:
      - app_network
    depends_on:
      - redis
    restart: always

  bot_main:
    build:
      context: .
      dockerfile: Dockerfile
    command: python bot/bot_main.py
    environment:
      - REDIS_URL=redis
      - LOGSTASH_HOST=logstash
      - LOGSTASH_PORT=5000
    networks:
      - app_network
    depends_on:
      - redis
    restart: always

  bot_stats:
    build:
      context: .
      dockerfile: Dockerfile
    command: python bot/bot_stats.py
    environment:
      - REDIS_URL=redis
      - LOGSTASH_HOST=logstash
      - LOGSTASH_PORT=5000
    networks:
      - app_network
    depends_on:
      - redis
    restart: always

volumes:
  redis_data:
    driver: local
  elasticsearch-data:
    driver: local

networks:
  app_network:
    driver: bridge